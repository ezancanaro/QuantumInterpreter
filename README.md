## QuantumInterpreter
# Dependencies:

Module Data.Matrix [link](https://hackage.haskell.org/package/matrix)
Module Number.CReal [link](https://hackage.haskell.org/package/numbers)

Both can be installed via cabal after issuing a **cabal update** command.

*cabal install matrix*
*cabal install numbers*

The interpreter makes use of language extensions via pragmas, defined for the GHC compiler, v 7.8 up. They could be removed without many troubles if your preferred version/compiler doesn't provide the same extensions with some care outlined below:

For the  Flexible and Overlapping Instances pragmas, used in the monadic version, the only application of those instances is on defining some pretty-print styles for pairs of lists, used on displaying the final State of a typechecking routine. Both pragmas can be safely removed by commenting the only instance of Show declared in the Main.hs file. When doing that, separating the State from the Result of the routine before showing results will achieve the same effect.

A problem arises with the removal of the ParallelListComp pragma, used on a list compreehension inside the *matchLinearCombinations* functions. In that case, the line wi = [reduceLinearE a (fst s) (snd $ ve !! (snd s)) | s <- sigmas | a <- alphas] needs to be modified, substituting the comprehension syntax for other code.


# Description

This project includes 2 implementations of a Typechecker for a functional reversible language with Quantum Control [arxiv paper ](https://arxiv.org/abs/1804.00952). The first version is implemented by the use of pure functions, threading the typing contexts throughout the function calls.

The second version was built relying on the State Monad to keep our contexts consistent. Both versions show the exact same behaviour, being complemented by the same evaluation routines in file Semantics.hs

Mostly, the differing implementations were meant as an experiment in the different Haskell styles, in regards to ease of source code comprehension and function prototyping. Monadic Style has the advantage of reducing the overcrowding of arguments on function calls and very explicitly showing equations that modify the state.

On the other hand, the pure version makes manipulating the contexts simpler, since the functional approach to values makes all modifications local to the subtree generated by each function call. In the end, both versions perform the exact same job.


# Running the examples

This project provides some pre-built examples of function evaluation and typechecking.

In order to us the monadic version: Having **stateMonadVersion** folder as working directory, use the -i ../ flag when compiling the code. (*ghc main.hs -i../*).

All of the pre-built examples can be run by compiling the code (E.g.: ghc main.hs) and running the resulting executable file. A small text menu will be provided for selecting an example to be ran. It can also be ran iteratively via ghci by calling *main* after loading all modules.

Defining extra examples can be quite cumbersome without a parser, but the *Isodefinitons.hs* file coupled with the test functions should provide enough guidelines for the moment. Shoot me an e-mail and I'll be happy to talk about any questions.

# To Do
1. Build a syntax parser for the language.
2. Define better examples, preferably with a complete program.
2. Implement a generic starting loop function, that can receive a list of iso definitions and run the typechecker and evaluator from there.
3. Improve the error messages given when typechecking. Current ones are more suited for aiding the development of the actual typechecker than for providing helpfull information to the user.
4. Implement variable scoping/a way of dealing with variable capturing in higher-order isos. - Done for isos, should not be a problem on value variables but need to test it a bit more.
5. Read up on conditional importing modules, so that it can use the same main.hs for both monadic and pure typecheckers.

A couple of exensions could be cool:

  Implement the evaluator step-by-step, allowing the exploration of the terms structure along the whole proccess. Ideally, this would allow one to step both forwards and backwards in the evaluation.

  Investigate performance of the interpreter, optimizing functions and using parallelism to solve some known bottlenecks:  
  - The evaluation of linear combinations applied to isos. (Should be easy to make them run simultaneously)
  - Building the matrices for typechecking isos with more clauses. (Optimize code instead of using Data.Matrix ??)
  - Iso inversion.
  - Application of the algebraic Properties and the function dubbed TensorProuctRep (Combinations could definitely run in parallel, but would need refactoring)

  A nice undertaking would be, after having a working parser, moifying the evaluation functions so that they can keep track of the abstract data being evaluated in relation to it's syntactical counterpart, allowing us to point specifically to the code line generating an error, for instance.
